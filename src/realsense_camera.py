#!/usr/bin/env python3
"""
RealSenseç›¸æœºç®¡ç†æ¨¡å—
æ”¯æŒRealSenseæ·±åº¦ç›¸æœºå’Œæ™®é€šæ‘„åƒå¤´
"""
import cv2 as cv
import numpy as np
from typing import Tuple, Optional, Dict, Any
import time
import pyrealsense2 as rs
class RealSenseCamera:
    """
    RealSenseæ·±åº¦ç›¸æœºç®¡ç†ç±»
    """
    
    def __init__(self, width: int = 640, height: int = 480, fps: int = 30):
        """
        åˆå§‹åŒ–RealSenseç›¸æœº
        
        Args:
            width: å›¾åƒå®½åº¦
            height: å›¾åƒé«˜åº¦
            fps: å¸§ç‡
        """
        self.width = width
        self.height = height
        self.fps = fps
        
        # åˆå§‹åŒ–RealSenseç®¡é“
        self.pipeline = rs.pipeline()
        self.config = rs.config()
        
        # é…ç½®æµ
        self.config.enable_stream(rs.stream.depth, width, height, rs.format.z16, fps)
        self.config.enable_stream(rs.stream.color, width, height, rs.format.bgr8, fps)
        
        # æ·±åº¦å¯¹é½å™¨
        self.align = rs.align(rs.stream.color)
        
        # æ·±åº¦å¯è§†åŒ–
        self.depth_scale = None
        self.depth_visualizer = rs.colorizer()
        
        self.is_running = False
        
    def start(self) -> bool:
        """
        å¯åŠ¨ç›¸æœº
        
        Returns:
            bool: å¯åŠ¨æ˜¯å¦æˆåŠŸ
        """
        try:
            # å¯åŠ¨ç®¡é“
            profile = self.pipeline.start(self.config)
            
            # è·å–æ·±åº¦æ¯”ä¾‹
            depth_sensor = profile.get_device().first_depth_sensor()
            self.depth_scale = depth_sensor.get_depth_scale()
            
            self.is_running = True
            print(f"âœ… RealSenseç›¸æœºå¯åŠ¨æˆåŠŸ")
           
            
            return True
            
        except Exception as e:
            print(f"âŒ RealSenseç›¸æœºå¯åŠ¨å¤±è´¥: {e}")
            return False
    
    def get_frames(self) -> Tuple[Optional[np.ndarray], Optional[np.ndarray]]:
        """
        è·å–æ·±åº¦å¸§å’Œå½©è‰²å¸§
        
        Returns:
            Tuple[æ·±åº¦å¸§, å½©è‰²å¸§]: æ·±åº¦å›¾(ç±³)å’Œå½©è‰²å›¾
        """
        if not self.is_running:
            return None, None
            
        try:
            # ç­‰å¾…å¸§
            frames = self.pipeline.wait_for_frames()
            
            # å¯¹é½æ·±åº¦å¸§åˆ°å½©è‰²å¸§
            aligned_frames = self.align.process(frames)
            
            # è·å–å¯¹é½åçš„æ·±åº¦å¸§å’Œå½©è‰²å¸§
            depth_frame = aligned_frames.get_depth_frame()
            color_frame = aligned_frames.get_color_frame()
            
            if not depth_frame or not color_frame:
                return None, None
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            depth_image = np.asanyarray(depth_frame.get_data())
            color_image = np.asanyarray(color_frame.get_data())
            
            # è½¬æ¢æ·±åº¦å•ä½ä¸ºç±³
            if self.depth_scale:
                depth_image = depth_image.astype(np.float32) * self.depth_scale
            
            return depth_image, color_image
            
        except Exception as e:
            print(f"âŒ è·å–å¸§å¤±è´¥: {e}")
            return None, None
    
    def create_depth_visualization(self, depth_image: np.ndarray) -> np.ndarray:
        """
        åˆ›å»ºæ·±åº¦å›¾å¯è§†åŒ–
        
        Args:
            depth_image: æ·±åº¦å›¾åƒ(ç±³)
            
        Returns:
            np.ndarray: å½©è‰²æ·±åº¦å›¾
        """
        if depth_image is None:
            return np.zeros((self.height, self.width, 3), dtype=np.uint8)
        
        # è½¬æ¢ä¸º16ä½æ·±åº¦å›¾ç”¨äºå¯è§†åŒ–
        if self.depth_scale and self.depth_scale > 0:
            depth_16bit = (depth_image / self.depth_scale).astype(np.uint16)
        else:
            # å¦‚æœæ²¡æœ‰æ·±åº¦æ¯”ä¾‹ï¼Œç›´æ¥ä½¿ç”¨æ·±åº¦å€¼
            depth_16bit = (depth_image * 1000).astype(np.uint16)  # è½¬æ¢ä¸ºæ¯«ç±³
        
        # ä½¿ç”¨OpenCVçš„é¢œè‰²æ˜ å°„è¿›è¡Œå¯è§†åŒ–
        # å°†æ·±åº¦å€¼å½’ä¸€åŒ–åˆ°0-255èŒƒå›´
        depth_normalized = cv.normalize(depth_16bit, None, 0, 255, cv.NORM_MINMAX, dtype=cv.CV_8U)
        
        # åº”ç”¨é¢œè‰²æ˜ å°„
        colorized_image = cv.applyColorMap(depth_normalized, cv.COLORMAP_JET)
        
        return colorized_image
    
    def get_camera_info(self) -> Dict[str, Any]:
        """
        è·å–ç›¸æœºä¿¡æ¯
        
        Returns:
            Dict: ç›¸æœºä¿¡æ¯
        """
        return {
            'type': 'RealSense',
            'width': self.width,
            'height': self.height,
            'fps': self.fps,
            'depth_scale': self.depth_scale,
            'is_running': self.is_running
        }
    
    def is_available(self) -> bool:
        """
        æ£€æŸ¥ç›¸æœºæ˜¯å¦å¯ç”¨
        
        Returns:
            bool: ç›¸æœºæ˜¯å¦å¯ç”¨
        """
        return self.is_running
    
    def cleanup(self):
        """
        æ¸…ç†èµ„æº
        """
        if self.is_running:
            self.pipeline.stop()
            self.is_running = False
            print("âœ… RealSenseç›¸æœºå·²åœæ­¢")





def create_camera(**kwargs) -> Any:
    """
    ç›¸æœºå·¥å‚å‡½æ•°ï¼ˆä»…RealSenseï¼‰
    
    Args:
        **kwargs: RealSense åˆå§‹åŒ–å‚æ•°ï¼ˆå¦‚ width, height, fpsï¼‰
        
    Returns:
        ç›¸æœºå¯¹è±¡ï¼ˆRealSenseCameraï¼‰
    """
 
    camera = RealSenseCamera(**kwargs)
    if camera.start():
        return camera
    raise RuntimeError("Failed to start RealSense camera")


def main():
    """
    æµ‹è¯•ç›¸æœºåŠŸèƒ½
    """
    print("ğŸš€ æµ‹è¯•ç›¸æœºåŠŸèƒ½...")
    
    # åˆ›å»ºç›¸æœºï¼ˆä»…RealSenseï¼‰
    camera = create_camera()
    
    if not camera.is_available():
        print("âŒ ç›¸æœºä¸å¯ç”¨")
        return
    
    print(f"ğŸ“· ç›¸æœºä¿¡æ¯: {camera.get_camera_info()}")
    
    try:
        frame_count = 0
        while frame_count < 100:  # æµ‹è¯•100å¸§
            depth_frame, color_frame = camera.get_frames()
            
            if depth_frame is not None and color_frame is not None:
                # æ˜¾ç¤ºå½©è‰²å›¾
                cv.imshow('Color Frame', color_frame)
                
                # æ˜¾ç¤ºæ·±åº¦å›¾
                depth_vis = camera.create_depth_visualization(depth_frame)
                cv.imshow('Depth Frame', depth_vis)
                
                frame_count += 1
                if frame_count % 10 == 0:
                    print(f"å¤„ç†å¸§: {frame_count}")
                
                # æŒ‰'q'é€€å‡º
                if cv.waitKey(1) & 0xFF == ord('q'):
                    break
            else:
                print("âŒ æ— æ³•è·å–å¸§")
                break
    
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­")
    
    finally:
        camera.cleanup()
        cv.destroyAllWindows()
        print("âœ… æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    main()
